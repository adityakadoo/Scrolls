<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=author content><meta name=description content="Notes of CS-310 Automata Theory course"><link rel=icon href=https://adityakadoo.github.io/Scrolls/favicon.ico><meta name=keywords content=" hugo  latex  theme "><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css integrity=sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js integrity=sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],ignoredTags:["script","noscript","style","textarea","pre","code","option"],throwOnError:!1})})</script><meta property="og:title" content="Automata Theory"><meta property="og:description" content="Notes of CS-310 Automata Theory course"><meta property="og:type" content="article"><meta property="og:url" content="https://adityakadoo.github.io/Scrolls/courses/automata_theory/"><meta property="og:image" content="https://adityakadoo.github.io/Scrolls/courses/automata_theory/images/thumbnail.png"><meta property="article:section" content="courses"><meta property="article:published_time" content="2022-08-19T17:00:34+05:30"><meta property="article:modified_time" content="2022-08-19T17:00:34+05:30"><link rel=canonical href=https://adityakadoo.github.io/Scrolls/courses/automata_theory/><meta itemprop=name content="Automata Theory"><meta itemprop=description content="Notes of CS-310 Automata Theory course"><meta itemprop=datePublished content="2022-08-19T17:00:34+05:30"><meta itemprop=dateModified content="2022-08-19T17:00:34+05:30"><meta itemprop=wordCount content="4510"><meta itemprop=image content="https://adityakadoo.github.io/Scrolls/courses/automata_theory/images/thumbnail.png"><meta itemprop=keywords content="Computer-Science,"><link media=screen rel=stylesheet href=https://adityakadoo.github.io/Scrolls/css/common.css><link media=screen rel=stylesheet href=https://adityakadoo.github.io/Scrolls/css/content.css><title>Automata Theory - Scrolls</title><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://adityakadoo.github.io/Scrolls/courses/automata_theory/images/thumbnail.png"><meta name=twitter:title content="Automata Theory"><meta name=twitter:description content="Notes of CS-310 Automata Theory course"><link rel=stylesheet href=https://adityakadoo.github.io/Scrolls/css/single.css></head><body><div id=wrapper><header id=header><h1><a href=https://adityakadoo.github.io/Scrolls/>Scrolls</a></h1><nav><span class=nav-bar-item><a class=link href=/Scrolls/>Post</a></span>
<span class=nav-bar-item><a class=link href=/Scrolls/post/>Archives</a></span>
<span class=nav-bar-item><a class=link href=/Scrolls/about/>About</a></span></nav></header><main id=main class=post><article class=content><h2 id=resources>Resources</h2><ul><li><h3 id=hopcrot-motwani-ullmanhttpswww-2dcubaarstaffbecherhopcroft-motwani-ullman-2001pdf><a href=https://www-2.dc.uba.ar/staff/becher/Hopcroft-Motwani-Ullman-2001.pdf>Hopcrot-Motwani-Ullman</a></h3></li></ul><h2 id=central-concepts>Central Concepts</h2><h4 id=alphabets>Alphabets</h4><dl><dt>Alphabet $ (\Sigma) $</dt><dd>An <em><strong>alphabet</strong></em> is a finite nonempty set of symbols.</dd></dl><ol><li>$ \Sigma= \{1, 0\} $</li><li>$ \Sigma = \{a,b,&mldr;,z\}$</li></ol><h4 id=strings>Strings</h4><dl><dt>String $(w)$</dt><dd>A <em><strong>string</strong></em> is a finite sequence of symbols chosen from $ \Sigma $.</dd><dt>Empty String $(\epsilon)$</dt><dd>The <em><strong>empty string</strong></em> is a string with zero symbols.</dd><dt>Length of a string</dt><dd>$|w|=\#$ Symbols in $w$</dd></dl><blockquote><p>$|\epsilon|=0$</p></blockquote><dl><dt>Power of Alphabets</dt><dd><ul><li>$\Sigma^k=\{w:|w|=k\}$</li><li>$\Sigma^+=\Sigma^1\cup\Sigma^2\cup&mldr;$</li><li>$\Sigma^*=\Sigma^+\cup\{\epsilon\}$</li></ul></dd></dl><blockquote><p>$\Sigma^0= \{\epsilon\}$</p></blockquote><dl><dt>Concatenation of Strings</dt><dd>For strings $w_1$ and $w_2$, their <em><strong>concatenation</strong></em> is $w_1w_2$.</dd></dl><blockquote><p>$|w_1w_2| = |w_1|+|w_2|$</p></blockquote><h4 id=languages>Languages</h4><dl><dt>Language $(L)$</dt><dd>A <em><strong>language</strong></em> over $\Sigma$ is basically $L\sube\Sigma^*$.</dd></dl><blockquote><p>A common way on defining languages is to use set-builder form as,
$\{w\in\Sigma^*:$ something about $w\}$.</p></blockquote><dl><dt>Empty Language $(\empty)$</dt><dd>The <em><strong>empty language</strong></em> contains no words.</dd></dl><blockquote><p>$\empty\ne\{\epsilon\}$</p></blockquote><h4 id=problems>Problems</h4><dl><dt>Problem</dt><dd>Any <em><strong>problem</strong></em> is, given a $w$ in $\Sigma^*$, decide whether or not $w$ is in $L$.</dd></dl><blockquote><p>If testing membership in $L_X$ is hard, then compiling programs in programming language $X$ is hard.</p></blockquote><h2 id=finite-state-automaton>Finite State Automaton</h2><h3 id=dfa>DFA</h3><dl><dt>Deterministic Finite Automaton $(\mathcal D(Q,\Sigma,\delta,q_0,F) )$</dt><dd><ol><li>A finite set of <em>states</em> $(Q)$.</li><li>A finite set of <em>input symbols</em> $(\Sigma)$.</li><li>A <em>transition function</em> $(\delta:Q\times\Sigma\rightarrow Q)$</li><li>A <em>start state</em> $(q_0\in Q)$</li><li>A set of <em>final states</em> $F\sube Q$</li></ol></dd><dt>Transition diagram $(G_{\mathcal D}(V,E))$</dt><dd><ol><li>$V=\{q:q\in Q\}$</li><li>$E=\{q_1\xrightarrow{a}q_2:a\in\Sigma\text{ and }\delta(q_1,a)=q_2\}$</li><li>An arrow pointing into $q_0$.</li><li>All nodes in $F$ are denoted with double circle.</li></ol></dd><dt>Extended transition function $(\hat\delta:Q\times\Sigma^*\rightarrow Q)$</dt><dd><ul><li><em>Basis</em>: $\hat\delta(q,\epsilon)=q$</li><li><em>Induction</em>: $\hat\delta(q,w)=\delta(\hat\delta(q,w[:-1]),w[-1])$</li></ul></dd><dt>Language of DFA $(L(\mathcal D))$</dt><dd>$$
L(\mathcal D)=\{w\in\Sigma:\hat\delta(q_0,w)\in F\}
$$</dd></dl><h3 id=nfa>NFA</h3><dl><dt>Nondeterministic Finite Automaton $(\mathcal N(Q,\Sigma,\delta,q_0,F) )$</dt><dd><ol><li>A finite set of <em>states</em> $(Q)$.</li><li>A finite set of <em>input symbols</em> $(\Sigma)$.</li><li>A <em>transition function</em> $(\delta:Q\times\Sigma\rightarrow\mathcal P(Q))$</li><li>A <em>start state</em> $(q_0\in Q)$</li><li>A set of <em>final states</em> $F\sube Q$</li></ol></dd></dl><blockquote><p>$\mathcal P(S)=\{A:A\sube S\}$</p></blockquote><dl><dt>Extended transition function $(\hat\delta:Q\times\Sigma^*\rightarrow P(Q))$</dt><dd><ul><li><em>Basis</em>: $\hat\delta(q,\epsilon)=\{q\}$</li><li><em>Induction</em>: $\hat\delta(q,w)=\bigcup_{p\in \hat\delta(q,w[:-1])}\delta(p,w[-1])$</li></ul></dd><dt>Language of NFA $(L(\mathcal N))$</dt><dd>$$
L(\mathcal N)=\{w\in\Sigma:\hat\delta(q_0,w)\cap F\ne\empty\}
$$</dd></dl><h4 id=equivalence-of-dfa-and-nfa>Equivalence of DFA and NFA</h4><p>Given an NFA $(\mathcal N=\{Q_N,\Sigma,\delta_N,q_0,F_N\})$ it can be converted to a DFA $\mathcal D=\{Q_D,\Sigma,\delta_D,\{q_0\},F_D\}$ such that $L(\mathcal D)=L(\mathcal N)$ using <em><strong>subset construction</strong></em> method.</p><ol><li>$Q_D=P(Q_N)$</li><li>$F_D=\{S\sube Q_N:S\cap F_N\ne\empty\}$</li><li>$\delta_D:P(Q_N)\times\Sigma\rightarrow P(Q_N)$ is defined as,
$$
\delta_D(S,a)=\bigcup_{p\in S}\delta_N(p,a)
$$</li></ol><h5 id=theorem--lmathcal-dlmathcal-n-ie-forall-winsigma-hatdelta_dq_0whatdelta_nq_0w><strong>Theorem</strong> : $L(\mathcal D)=L(\mathcal N)$ i.e. $\forall w\in\Sigma,\\ \hat\delta_D(\{q_0\},w)=\hat\delta_N(q_0,w)$</h5><dl><dt>Proof</dt><dd><ul><li><em>Basis</em>: For $w=\epsilon,\\ \hat\delta_D(\{q_0\},w)=\{q_0\}$ and $\hat\delta_N(q_0,w)=\{q_0\}$</li><li><em>Induction</em>: As $\hat\delta_N(q_0,w[:-1])=\hat\delta_D(\{q_0\},w[:-1])$
$$
\hat\delta_N(q_0,w)=\bigcup_{p\in\hat\delta_N(q_0,w[:-1])}\delta_N(p,w[-1])
$$
$$
\hat\delta_D(\{q_0\},w)=\delta_D(\hat\delta_D(\{q_0\},w[:-1]),w[-1])=\bigcup_{p\in\hat\delta_D(\{q_0\},w[:-1])}\delta_N(p,w[-1])
$$
$$
\therefore\hat\delta_D(\{q_0\},w)=\hat\delta_N(q_0,w)
$$</li></ul></dd></dl><h5 id=theorem--a-language-l-is-accepted-by-some-dfa-iff-l-is-accepted-by-some-nfa><strong>Theorem</strong> : A language $L$ is accepted by some DFA iff $L$ is accepted by some NFA.</h5><blockquote><p>A bad case for subset construction is $L=\{w\in\{1,0\}^*:w[-n]=1\}$</p></blockquote><h3 id=epsilon-nfa>$\epsilon$-NFA</h3><dl><dt>Finite Automaton with $\epsilon$-transition $(\mathcal A(Q,\Sigma,\delta,q_0,F))$</dt><dd>It is defined similar to the NFA with only difference in $\delta:Q\times\Sigma\cup\{\epsilon\}\rightarrow P(Q)$.</dd><dt>Epsilon Closure $(\text{Ecl}(.))$</dt><dd><ul><li><em>Basis</em>: $q\in\text{Ecl}(q)$</li><li><em>Induction</em>: If $p\in\text{Ecl}(q)$ and $r\in\delta(p,\epsilon)$ then $r\in\text{Ecl}(q)$</li></ul></dd><dt>Extended Transition Function $(\hat\delta(.,.))$</dt><dd><ul><li><em>Basis</em>: $\hat\delta(q,\epsilon)=\text{Ecl}(q)$</li><li><em>Induction</em>: $$\hat\delta(q,w)=\bigcup_{r\in\bigcup_{p\in\hat\delta(q,w[:-1])}\delta(p,w[-1])}\text{Ecl}(r)$$</li></ul></dd></dl><h4 id=eliminating-epsilon-transitions>Eliminating $\epsilon$-transitions</h4><p>Given an $\epsilon$-NFA $\mathcal A=\{Q_A,\Sigma,\delta_A,q_0,F_A\}$ it can be converted to a DFA $\mathcal D=\{Q_D,\Sigma,\delta_D,\{q_D\},F_D\}$ such that $L(\mathcal D)=L(\mathcal A)$ as follows,</p><ol><li>$Q_D=\mathcal P(Q_A)$</li><li>$q_D=\text{Ecl}(q_0)$</li><li>$F_D=\{S:S\in Q_D$ and $S\cap F_A\ne\empty\}$</li><li>$\delta_D:Q_D\times\Sigma$ is defined as follows,
$$
\delta_D(S,a)=\bigcup_{r\in\bigcup_{p\in S}\delta_A(p,a)}\text{Ecl}(r)
$$</li></ol><h5 id=theorem--a-language-l-is-accepted-by-some-epsilon-nfa-iff-l-is-accepted-by-some-dfa><strong>Theorem</strong> : A language $L$ is accepted by some $\epsilon$-NFA iff $L$ is accepted by some DFA.</h5><dl><dt>Proof</dt><dd>Use the above procedure to create a DFA.<ul><li><em>Basis</em>: Since $\hat\delta_A(q_0, \epsilon)=\text{Ecl}(q_0)$ and $\hat\delta_D(q_D, \epsilon)=\hat\delta_D(\text{Ecl}(q_0),\epsilon)=\text{Ecl}(q_0)$, $\hat\delta_A(q_0, \epsilon) = \hat\delta_D(q_D, \epsilon)$</li><li><em>Induction</em>: As $\hat\delta_A(q_0, w[:-1])=\hat\delta_D(q_D,w[:-1])$ and,
$$
\hat\delta_A(q_0,w)=\bigcup_{r\in\bigcup_{p\in\hat\delta_A(q_0, w[:-1])}\delta_A(p,w[-1])}\text{Ecl}(r)
$$
and $\hat\delta_D(q_D,w)$ is defined in a similar way,
$$
\therefore\hat\delta_A(q_0, w)=\hat\delta_D(q_D,w)
$$</li></ul></dd></dl><h2 id=regular-expressions>Regular Expressions</h2><p>Operators on Regular Languages</p><dl><dt>Union $(\cup)$</dt><dd>The union of two languages $L$ and $M$ is defined as $L\cup M$.</dd><dt>Concatenation $(\cdot)$</dt><dd>The concatenation of two languages $L$ and $M$ is defined as $LM=\{x\cdot y\text{ or }xy:x\in L,y\in M\}$.</dd><dt>Kleene closure $(^{*})$</dt><dd>The Kleene closure of a language $L$ is defined inductively as,<ul><li><em>Basis</em>: $\epsilon\in L^*$</li><li><em>Induction</em>: If $w\in L^*$ and $x\in L$ then, $wx\in L^*$</li></ul></dd><dt>RegEx $(\boldsymbol R)$</dt><dd><ul><li><em>Basis</em>: It contains 2 parts:<ol><li>The constants $\boldsymbol{\epsilon}$ and $\boldsymbol{\empty}$ are regex such that $L(\boldsymbol{\epsilon})=\{\epsilon\}$ and $L(\boldsymbol{\empty})=\empty$</li><li>Every symbol $\boldsymbol{a}$ such that $a\in\Sigma$ is a regex then $L(\boldsymbol{a})=\{a\}$</li></ol></li><li><em>Induction</em>: There are four parts for the induction step:<ol><li>$L(\boldsymbol E+\boldsymbol F)=L(\boldsymbol E)\cup L(\boldsymbol F)$</li><li>$L(\boldsymbol E\boldsymbol F)=L(\boldsymbol E)L(\boldsymbol F)$</li><li>$L(\boldsymbol E^*)=(L(\boldsymbol E))^*$</li><li>$L((\boldsymbol E))=L(\boldsymbol E)$</li></ol></li></ul></dd></dl><blockquote><p>$* > . > +$</p></blockquote><h3 id=equivalence-to-finite-automata>Equivalence to Finite Automata</h3><h4 id=dfa-to-regex>DFA to RegEx</h4><h5 id=theorem-if-llmathcal-d-for-some-dfa-mathcal-d-then-there-is-a-regular-expression-boldsymbol-r-such-that-llboldsymbol-r><strong>Theorem</strong>: If $L=L(\mathcal D)$ for some DFA $\mathcal D$, then there is a regular expression $\boldsymbol R$ such that $L=L(\boldsymbol R)$</h5><dl><dt>Proof</dt><dd>Let the DFA have $n$ nodes each labelled with a number from $[1,n]$.</dd></dl><blockquote><p>$\boldsymbol R_{ij}^{(k)}=\{w:\hat\delta(i,w)=j$ and $\forall t$ such that $0&lt;t&lt;|w|-1,\ \hat\delta(i,w[:t])\le k\}$</p></blockquote><ul><li><em>Basis</em>: Let $S=\{a:\delta(i,a)=j\}$. If $S=\empty$ then $\boldsymbol R_{ij}^{(0)}=\empty$ else $\boldsymbol R_{ij}^{(0)}=\sum_{a\in S}a$</li><li><em>Induction</em>:
$$
\boldsymbol R_{ij}^{(k)}=\boldsymbol R_{ij}^{(k-1)} + \boldsymbol R_{ik}^{(k-1)}\cdot(\boldsymbol R_{kk}^{(k-1)})^*\cdot\boldsymbol R_{kj}^{(k-1)}
$$</li></ul><h4 id=regex-to-automata>RegEx to Automata</h4><h5 id=theorem-every-language-accepted-by-a-regular-expression-is-also-accepted-by-a-finite-automaton><strong>Theorem</strong>: Every language accepted by a regular expression is also accepted by a finite automaton.</h5><dl><dt>Proof</dt><dd>Let $L=L(\boldsymbol R)$ for some regular expression $\boldsymbol R$. We show that $L=L(\mathcal A)$ for some $\epsilon$-NFA $\mathcal A$ with:</dd></dl><ol><li>Exactly one accepting state.</li><li>No arcs into the initial state.</li><li>No arcs out of the accepting state.</li></ol><ul><li><p><em>Basis</em>: For the 3 base cases:</p><ol><li><p>$\boldsymbol \empty$</p><p><img src=images/DFAtoRegEx_7-13.png alt=Emtpy></p></li><li><p>$\boldsymbol \epsilon$</p><p><img src=images/DFAtoRegEx_6-44.png alt=Emtpy></p></li><li><p>$\boldsymbol a\in\Sigma$</p><p><img src=images/DFAtoRegEx_7-24.png alt=Emtpy></p></li></ol></li><li><p><em>Induction</em>:</p><ol><li><p>$\boldsymbol R+\boldsymbol S$</p><p><img src=images/DFAtoRegEx_7-48.png alt=Emtpy></p></li><li><p>$\boldsymbol R\boldsymbol S$</p><p><img src=images/DFAtoRegEx_8-10.png alt=Emtpy></p></li><li><p>$\boldsymbol R^{*}$</p><p><img src=images/DFAtoRegEx_8-26.png alt=Emtpy></p></li></ol></li></ul><h3 id=algebraic-laws>Algebraic Laws</h3><h4 id=associativity-and-commutativity>Associativity and Commutativity</h4><ul><li>$L+M=M+L$</li><li>$(L+M)+N=L+(M+N)$</li><li>$(LM)N$=$L(MN)$</li></ul><h4 id=identities-and-annihilators>Identities and Annihilators</h4><ul><li>$\empty+L=L+\empty=L$</li><li>$\epsilon L=L\epsilon=L$</li><li>$\empty L=L\empty=\empty$</li></ul><h4 id=distributive-laws>Distributive Laws</h4><ul><li>$L(M+N)=LM+LN$</li><li>$(M+N)L=ML+NL$</li></ul><h4 id=idempotent-law>Idempotent Law</h4><ul><li>$L+L=L$</li></ul><h4 id=laws-with-closure>Laws with Closure</h4><ul><li>$(L^*)^*=L^*$</li><li>$\empty^*=\epsilon$</li><li>$\epsilon^*=\epsilon$</li></ul><blockquote><p>$L^+=LL^*$</p></blockquote><ul><li>$L^*=L^++\epsilon$</li></ul><blockquote><p>$L?=\epsilon+L$</p></blockquote><ul><li>$(L^*M^*)^*=(L+M)^*$</li></ul><h2 id=properties-of-rls>Properties of RLs</h2><h3 id=pumping-lemma-for-rls>Pumping Lemma for RLs</h3><h4 id=statement-of-ppumping-lemma>Statement of PPumping Lemma</h4><h5 id=theorem-for-all-l-such-that-l-is-a-regular-language-there-exists-a-constant-n-such-that-for-all-wge-n-we-can-break-w-into-three-strings-wxyz-such-that><strong>Theorem</strong>: For all $L$ such that $L$ is a regular language, there exists a constant $n$ such that for all $|w|\ge n$ we can break $w$ into three strings, $w=xyz$, such that:</h5><h5 id=1-yneepsilon>1. $y\ne\epsilon$</h5><h5 id=2-xyle-n>2. $|xy|\le n$</h5><h5 id=3-forall-kge0xykzin-l>3. $\forall k\ge0,xy^kz\in L$</h5><dl><dt>Proof</dt><dd>Let $L=L(\mathcal D)$ be a regular language for DFA $\mathcal D$. Consider a $w$ such that $|w|\ge n$.
We define,
$$
S = \{q
_i:0\le i\le n,\hat\delta(q_0,w[:i])=q_i\}
$$
As size of $S$ is $n+1$ there must be two $q_i$ and $q_j$ such that $q_i=q_j$ by Pigeon-hole principle. We can break $w$ as,<ol><li>$x=w[:i]$</li><li>$y=w[i:j]$</li><li>$z=w[j:]$</li></ol></dd></dl><h4 id=proving-languages-not-to-be-regular>Proving languages not to be Regular</h4><p>We do a game between 2 players as follows:</p><ol><li>Player 1 picks the language $L$ to be proved nonregular.</li><li>Player 2 picks $n$, but doesn&rsquo;t reveal to player 1 what $n$ is; player 1 must devise a play for all possible $n$&rsquo;s.</li><li>Player 1 picks $w$, which may depend on $n$ and which must be of length at least $n$ and $w\in L$.</li><li>Player 2 divides $w$ into $x$, $y$ and $z$, obeying the constraints that are stipulated in the pumping lemma; $y\ne\epsilon$ and $|xy|\le n$ and doesn&rsquo;t tell player 1 what $x$, $y$ and $z$ are.</li><li>Player 1 &ldquo;wins&rdquo; by picking $k$, which may be a function of $n$, $x$, $y$ and $z$, such that $xy^kz$ is not in $L$.</li></ol><p>Thus $L$ must not be regular as it doesn&rsquo;t follow the pumping lemma.</p><h3 id=closure-properties>Closure Properties</h3><h4 id=closure-under-boolean-operations>Closure under Boolean Operations</h4><blockquote><p>$\boldsymbol R_L =$ regular expression for language $L$</p></blockquote><h5 id=theorem-if-l-and-m-are-regular-then-lcup-m-is-also-regular><strong>Theorem</strong>: If $L$ and $M$ are regular then $L\cup M$ is also regular.</h5><dl><dt>Proof</dt><dd>$L\cup M=L(\boldsymbol R_L+\boldsymbol R_M)$</dd></dl><h5 id=theorem-if-l-is-regular-then-so-is-bar-l><strong>Theorem</strong>: If $L$ is regular then so is $\bar L$.</h5><dl><dt>Proof</dt><dd>Convert $\boldsymbol R_L$ to DFA and take complement of it and construct the regular expression again to get $\boldsymbol R_{\bar L}$</dd></dl><h5 id=theorem-if-l-and-m-are-regular-then-lcap-m-is-also-regular><strong>Theorem</strong>: If $L$ and $M$ are regular then $L\cap M$ is also regular.</h5><dl><dt>Proof</dt><dd>$L\cap M=\overline{\overline L\cup\overline M}$</dd></dl><h5 id=theorem-if-l-and-m-are-regular-then-l-m-is-also-regular><strong>Theorem</strong>: If $L$ and $M$ are regular then $L-M$ is also regular.</h5><dl><dt>Proof</dt><dd>$L-M=L\cap\overline M$</dd></dl><h4 id=reversal>Reversal</h4><blockquote><p>$L^R$ is defined as the reversal of the language $L$.</p></blockquote><h5 id=theorem-if-l-is-regular-language-then-so-is-lr><strong>Theorem</strong>: If $L$ is regular language then so is $L^R$.</h5><dl><dt>Proof</dt><dd>Construct the DFA $\mathcal D$ of $L$ and reverse all the edges of $\mathcal D$ and make final states as start states and start states as end states. This will make an NFA accepting only reverse of string in $L$.</dd></dl><h3 id=descision-properties>Descision Properties</h3><h4 id=converting-among-representations>Converting among Representations</h4><ul><li>NFA to DFA: $\mathcal O(n^32^n)$</li><li>DFA to NFA: $\mathcal O(n)$</li><li>DFA to RegEx: $\mathcal O(n^34^n)$</li><li>NFA to RegEx: $\mathcal O(n^34^{n^32^n})$</li><li>RegEx to $\epsilon$-NFA: $\mathcal O(n^3)$</li></ul><h4 id=testing-emptiness-of-regular-languages>Testing Emptiness of Regular Languages</h4><p>Given a DFA apply BFS to check if any final state is reachable from the start state.</p><p>For a Regular Expression,</p><ul><li><em>Basis</em>: $\empty$ is the empty language.</li><li><em>Induction</em>: Four cases must be considered:<ol><li>$R=R_1+R_2$ then $L(R)$ is empty iff both $L(R_1)$ and $L(R_2)$ are empty.</li><li>$R=R_1R_2$ then $L(R)$ is empty iff $L(R_1)$ or $L(R_2)$ is empty.</li><li>$R=R_1^*$ then $L(R)$ is not empty.</li><li>$R=(R_1)$ then $L(R)$ is empty iff $L(R_1)$ is empty.</li></ol></li></ul><h4 id=testing-membership-in-a-regular-language>Testing Membership in a Regular Language</h4><p>For a string $w$ with $|w|=n$ and $s$ states,</p><ul><li>DFA: $\mathcal O(n)$</li><li>$\epsilon$-NFA: $\mathcal O(ns^2)$</li><li>RegEx: $\mathcal O(ns^2)$</li></ul><h3 id=equivalence-and-minimization>Equivalence and Minimization</h3><dl><dt>Equivalent States $(p,q)$</dt><dd>For all input strings $w$, $\hat\delta(p,w)$ is an accepting state iff $\hat\delta(q,w)$ is an accepting state.</dd></dl><h4 id=testing-equivalence-of-states>Testing Equivalence of States</h4><p>Finding all pairs of distinguishable states by table method.</p><ul><li><em>Basis</em>: If $p$ is an accepting state and $q$ is a nonaccepting, then the pair $\{p,q\}$ is distinguishable.</li><li><em>Induction</em>: Let $r=\delta(p,a)$ and $s=\delta(q,a)$ then $p$ and $q$ are distinguishable if $r$ and $s$ are known to be distinguishable.</li></ul><h5 id=theorem-any-pair-that-is-left-indistinguishable-from-the-table-filling-algorithm-is-equivatent><strong>Theorem</strong>: Any pair that is left indistinguishable from the table-filling algorithm is equivatent.</h5><h4 id=minimization-of-dfas>Minimization of DFA&rsquo;s</h4><h5 id=theorem-the-equivalence-of-states-is-transitive-that-is-if-in-some-dfa-mathcal-dqsumdeltaq_0f-we-find-that-states-p-and-q-are-equivalent-and-we-also-find-that-q-and-r-are-equivalent-then-it-must-be-that-p-and-r-are-equivalent><strong>Theorem</strong>: The equivalence of states is transitive. That is, if in some DFA $\mathcal D=(Q,\sum,\delta,q_0,F)$ we find that states $p$ and $q$ are equivalent, and we also find that $q$ and $r$ are equivalent, then it must be that $p$ and $r$ are equivalent.</h5><p>Therefore the &ldquo;equivalence of states&rdquo; is an equivalence relation over $Q$. This means we can divide the $Q$ into different equivalence classes and the minimal DFA needs to have at least these many states representing each equivalence class.</p><h2 id=context-free-grammars>Context-free Grammars</h2><dl><dt>CFG $(\mathcal G(V,T,P,S))$</dt><dd><ul><li><em><strong>Terminals</strong></em> $(T\sube\{a,\cdots,z\})$
: Set of symbols of the language being defined.</li><li><em><strong>Variables</strong></em> $(V\sube\{A,\cdots,Z\})$
: Aka nonterminal or syntactic categories; Set of finite variables that each represent a language.</li><li><em><strong>Start Symbol</strong></em> $(S)$
: A special variable which represents the required language.</li><li><em><strong>Rules</strong></em> $(P)$
: A set of rules describing recursive definitions of variables such that,
$$
P\sube\{A_0\rightarrow w_0|A_0\in V\text{ and }w_0\in(T\cup V)^*\}
$$</li></ul></dd><dt>Derivation Relation $(\Rightarrow)$</dt><dd>$$
R_{\boldsymbol{\Rightarrow}}=\{(\alpha A\beta,\alpha\gamma\beta)|A\rightarrow\gamma\in P\}
$$
So in short $\alpha A\beta\Rightarrow\alpha\gamma\beta$.</dd><dt>Extended Derivation Relation $(\xRightarrow{*})$</dt><dd>We can extend the above relation to a more powerful &ldquo;derivation in multiple steps&rdquo; relation $\xRightarrow{*}$ as,<ul><li><em>Basis</em>: For any string $\alpha$, $\alpha\xRightarrow{*}\alpha$</li><li><em>Induction</em>: If $\alpha\xRightarrow{*}\beta$ then $\beta\Rightarrow\gamma$ then $\alpha\xRightarrow{*}\gamma$</li></ul></dd><dt>Leftmost Derivation</dt><dd>While deriving the leftmost string that occurs in a rule as head is always substituted first. This gives use new relations $\xRightarrow[lm]{}$ and $\xRightarrow[lm]{*}$.</dd><dt>Rightmost Derivation</dt><dd>Similarly we can also define the relations $\xRightarrow[rm]{}$ and $\xRightarrow[rm]{*}$</dd><dt>Language of a Grammar</dt><dd>The language $L$ given by a CFG $\mathcal G$ is defined as,
$$
L(\mathcal G) = \{w\in T^{*}| S\xRightarrow[\mathcal G]{*}w\}
$$</dd><dt>Sentential Forms</dt><dd>All the strings $\alpha\in(V\cup T)^{*}$ such that $S\xRightarrow{*}\alpha$ are sentential form.</dd></dl><p>Similar we can define <em><strong>right-sentential form</strong></em> and <em><strong>left-sentential form</strong></em>.</p><h3 id=parse-trees>Parse Trees</h3><dl><dt>Parse Trees</dt><dd>For a grammar $\mathcal G$ the parse tree is defined as,<ol><li>Each interior node is labelled by a variable in $V$.</li><li>Each leaf is either labelled by a variable or a terminal or $\epsilon$. If a leaf has $\epsilon$ as label then it must be an only child.</li><li>If an interior node is labeled $A$ and its children are labeled
$$
X_1,X_2,\dots,X_k
$$
then $A\rightarrow X_1X_2\dots X_k\in P$ and $A$ can have $\epsilon$ as child only if $A\rightarrow\epsilon\in P$.</li></ol></dd><dt>Yield</dt><dd>For a particular parse tree, the string obtained by joining the labels of the leafs in the parse tree.</dd></dl><p>More important parse trees are the ones where:</p><ul><li>Yield is a terminal string.</li><li>Root is labeled by the start symbol.</li></ul><h4 id=inference-derivation-and-parse-trees>Inference, Derivation and Parse Trees</h4><p>While describing a grammar $G$ and a string $w$ the following 5 are equivalent,</p><ol><li>The recursive inference procedure determines that terminal string $w$ is in th language $A$.</li><li>$A\xRightarrow{*}w$</li><li>$A\xRightarrow[lm]{*}e$</li><li>$A\xRightarrow[rm]{*}e$</li><li>There is a parse tree with root $A$ and yield $w$.</li></ol><h4 id=inference-to-trees>Inference to Trees</h4><h5 id=theorem--if-a-recursive-inference-procedure-gives-that-terminal-string-w-is-in-the-language-of-variable-a-then-there-is-a-parse-tree-with-root-a-and-yeild-w><strong>Theorem</strong> : If a recursive inference procedure gives that terminal string $w$ is in the language of variable $A$, then there is a parse tree with root $A$ and yeild $w$.</h5><dl><dt>Proof</dt><dd>Induction on the number of steps to infer that $w$ is in $A$.<ul><li>Basis: In a single step, inference procedure gets to $w$ from $A$. Thus, there must be a $A\rightarrow w\in P$. Therefore in the parse tree rooted at $A$ we can get the yield as $w$.</li><li>Induction: Let the fact $w$ in the language of $A$ be infered after $n+1$ steps and that the hypothesis for all inferences with $\le n$ steps.</li></ul><p>Let $A\rightarrow X_1X_2\cdots X_k$ be a rule used to expand $A$ in the inference. Break $w=w_1w_2\cdots w_k$ such that</p><ol><li>If $X_i$ is terminal then $w_i=X_i$</li><li>If $X_i$ is variable then by induction hypothesis there exist a tree rooted at $X_i$ and yield $w_i$.</li></ol><p>Now we construct the tree rooted at $A$ by adding $X_1,X_2,\dots,X_k$ as level one children and their trees as described above below them. Thus the yeild of this tree is $w$.</p></dd></dl><h4 id=trees-to-derivations>Trees to derivations</h4><h5 id=theorem--suppose-there-is-a-parse-tree-root-labeled-by-variable-a-and-with-yield-w-where-w-is-in-tast-then-there-is-a-leftmost-derivation-axrightarrowlmastw-in-grammar-g><strong>Theorem</strong> : Suppose there is a parse tree root labeled by variable $A$ and with yield $w$ where $w$ is in $T^{*}$. Then there is a leftmost derivation $A\xRightarrow[lm]{*}w$ in grammar $G$.</h5><dl><dt>Proof</dt><dd>On performing induction on the height of the tree. Similar to above proof.</dd></dl><h4 id=derivations-to-inferences>Derivations to Inferences</h4><h5 id=theorem--if-there-is-a-derivation-axrightarrowgastw-for-win-tast-then-recursive-inference-procedure-applied-to-g-determines-that-w-is-in-the-language-of-a><strong>Theorem</strong> : If there is a derivation $A\xRightarrow[G]{*}w$ for $w\in T^{*}$ then recursive inference procedure applied to $G$ determines that $w$ is in the language of $A$.</h5><dl><dt>Proof</dt><dd>On performing induction on the length of the derivation $A\xRightarrow{*}w$. Similar to above proof.</dd></dl><h2 id=push-down-automaton>Push-down Automaton</h2><dl><dt>Pushdown Automaton $(\mathcal P(Q,\Sigma,\Gamma,\delta,q_0,Z_0,F) )$</dt><dd><ol><li>A finite set of <em>states</em> $(Q)$.</li><li>A finite set of <em>input symbols</em> $(\Sigma)$.</li><li>A finite <em>stack alphabet</em> that can be push onto the stack $(\Gamma)$</li><li>A <em>transition function</em> $(\delta:Q\times\Sigma\cup\{\epsilon\}\times\Gamma\rightarrow\mathcal P(Q\times\Gamma^{*}))$ such that $(p,\gamma)\in\delta(q,a,X)$ means that on the input symbol $a$ we go from $q$ to $p$ and change the top of the stack from symbol $X$ to string $\gamma$</li><li>A <em>start state</em> $(q_0\in Q)$</li><li>The <em>stack start symbol</em> $(Z_0)$ that is empty stack has this at the top initially</li><li>A set of <em>final states</em> $F\sube Q$</li></ol></dd><dt>Transition Diagram $(G(V,E))$</dt><dd><ol><li>$V=\{q:q\in Q\}$</li><li>An arrow pointing into $q_0$</li><li>Double circle around states in $F$</li><li>$E=\{q\xrightarrow{a,X/\gamma}p:(p,\gamma)\in\delta(q,a,X)\}$</li></ol></dd><dt>Instantaneous Description $(ID=(q,w,\gamma))$</dt><dd><ol><li>$q$ is the state</li><li>$w$ is the remaining input</li><li>$\gamma$ is the stack contents</li></ol></dd><dt>Transition Relation $(\vdash\sube(ID)^2)$</dt><dd>If $(p,\alpha)\in\delta(q,a,X)$ then, $\forall w\in\Sigma^{*},\forall\beta\in\Gamma^{*}$
$$
(q,aw,X\beta)\vdash(p,w,\alpha\beta)
$$</dd><dt>Generalised Transition Relation $(\vdash^{*})$</dt><dd><ul><li><em>Basis</em>: $I\vdash^{*}I$ for all $ID\text{s}$</li><li><em>Induction</em>: If $I\vdash K$ and $K\vdash^{*}J$ then $I\vdash^{*}J$</li></ul></dd></dl><h5 id=theorem--if-qxalphavdashastpybeta-then-for-any-strings-w-in-sigmaast-and-gamma-in-gammaast-it-is-also-true-that-qxwalphagammavdashastpywbetagamma><strong>Theorem</strong> : If $(q,x,\alpha)\vdash^{*}(p,y,\beta)$, then for any strings $w$ in $\Sigma^{*}$ and $\gamma$ in $\Gamma^{*}$, it is also true that $(q,xw,\alpha\gamma)\vdash^{*}(p,yw,\beta\gamma)$</h5><h5 id=theorem--if-qxwalphavdashastpywbeta-then-qxalphavdashastpybeta><strong>Theorem</strong> : If $(q,xw,\alpha)\vdash^{*}(p,yw,\beta)$ then $(q,x,\alpha)\vdash^{*}(p,y,\beta)$</h5><h3 id=language-of-a-pda>Language of a PDA</h3><h4 id=acceptance-by-final-state>Acceptance by Final State</h4><p>$$
L(P) = \{w|(q_0,w,Z_0)\vdash^{*}(q,\epsilon,\alpha)\}
$$</p><h2 id=properties-of-cfls>Properties of CFLs</h2><h3 id=normal-forms-of-cfgs>Normal Forms of CFGs</h3><p>Every CFL can be converted to it&rsquo;s normal form by,</p><ol><li>Eliminate all the <em>useless symbols</em> i.e. those variables or terminals that do not appear in any derivation of a terminal string from the start symbol.</li><li>Eliminate all $\epsilon$<em>-productions</em>, those of the form $A\rightarrow\epsilon$ for some variable $A$.</li><li>Eliminate unit productions those of the fom $A\rightarrow B$ of variables $A$ and $B$.</li></ol><h4 id=eliminating-useless-symbols>Eliminating Useless Symbols</h4><dl><dt>Useful Symbol</dt><dd>A symbol $X\in T\cup V$ such that $S\xRightarrow{*}\alpha X\beta\xRightarrow{*}w$ where $w\in T^{*}$.</dd></dl><p>A useful symbol has to be both of the following things,</p><dl><dt>Generating</dt><dd>A symbol $X$ is generating if $X\xRightarrow{*}w$ for some terminal string $w$.</dd><dt>Reachable</dt><dd>A symbol $X$ is reachable if there is a derivation $S\xRightarrow{*}\alpha X\beta$ for some $\alpha$ and $\beta$.</dd></dl><h5 id=theorem--let-mathcal-g-be-a-cfg-and-assuming-lmathcal-gneempty-and-mathcal-g_1-be-the-grammar-we-obtain-by-eliminating><strong>Theorem</strong> : Let $\mathcal G$ be a CFG and assuming $L(\mathcal G)\ne\empty$ and $\mathcal G_1$ be the grammar we obtain by eliminating,</h5><h5 id=1-all-non-generating-symbols-and-productions-involving-any-of-these-symbols>1. All non-generating symbols and productions involving any of these symbols.</h5><h5 id=2-all-unreachable-symbols>2. All unreachable symbols.</h5><h5 id=thus-mathcal-g_1-has-no-useless-symbols-then-lmathcal-glmathcal-g_1>Thus $\mathcal G_1$ has no useless symbols then $L(\mathcal G)=L(\mathcal G_1)$.</h5><dl><dt>Proof</dt><dd>To show that $L(\mathcal G_1)=L(\mathcal G)$ we need to prove,<ul><li><p>$L(\mathcal G_1)\sube L(\mathcal G)$: Since we have only eliminated symbols and productions from $\mathcal G$ to get $\mathcal G_1$ it follows that $L(\mathcal G_1)\sube L(\mathcal G)$.</p></li><li><p>$L(\mathcal G)\sube L(\mathcal G_1)$: If $w$ is in $L(\mathcal G)$, then $S\xRightarrow[\mathcal G]{*}w$. Each symbol in this derivation is evidently both reachable and generating, so it also a derivation of $\mathcal G_1$. Thus, $S\xRightarrow[\mathcal G_1]{*}w$ i.e. $w\in L(\mathcal G_1)$.</p></li></ul></dd></dl><h4 id=computing-generating-and-reachable-symbols>Computing Generating and Reachable symbols</h4><p>For computing the <strong>generating symbols</strong> we use the following algorithm,</p><ul><li><em>Basis</em>: Every symbols in $T$ is obviously generating; it generates itself.</li><li><em>Induction</em>: Suppose there is a production $A\rightarrow\alpha$, and every symbols of $\alpha$ is already known to be generating. Then $A$ is generating.</li></ul><p>For computing the <strong>reachable symbols</strong> we use the following algorithm,</p><ul><li><em>Basis</em>: $S$ is surely reachable.</li><li><em>Induction</em>: Suppose $A$ is reachable and there is a production $A\rightarrow\alpha$, then all symbols in $\alpha$ are reachable.</li></ul><h4 id=eliminating-epsilon-productions>Eliminating $\epsilon$-Productions</h4><p>We have to prove is $L$ has a CFG then $L-\{\epsilon\}$ also has a CFG. But simply removing all productions that lead to $\epsilon$ may leave out certain words from the language. Thus we define the following procedure.</p><dl><dt>Nullable</dt><dd>A variable $A$ is nullable if $A\xRightarrow{*}\epsilon$.</dd></dl><p>Algorithm to identify all the nullable variables,</p><ul><li><em>Basis</em>: If $A\rightarrow\epsilon$ is a production of $G$, then $A$ is nullable.</li><li><em>Induction</em>: If there is a production $B\rightarrow C_1C_2\cdots C_k$ where each $C_i$ is nullable, then $B$ is nullable. Note that all $C_i$ have to be variables.</li></ul><p>Once all the nullable symbols have been determined, we construct a new grammar $\mathcal G_1$ whose set of productions $P_1$ is modified as follows.
For a production $A\rightarrow X_1X_2\cdots X_k$ of $P$, where $k\ge1$, suppose that $m$ of the $k$ $X_i$&rsquo;s are nullable symbols. We add all $2^m$ possible combinations of this production in $P_1$, where the nullable $X_i$&rsquo;s, in all possible combinations are present or absent. When $m=k$ i.e. all symbols $X_i$&rsquo;s are nullable then we do not include the case where all symbols are absent.</p><h5 id=theorem-if-grammar-mathcal-g_1-constructed-from-mathcal-g-by-the-above-construction-for-eliminating-epsilon-productions-then-lmathcal-g_1lmathcal-g-epsilon><strong>Theorem</strong>: If grammar $\mathcal G_1$ constructed from $\mathcal G$ by the above construction for eliminating $\epsilon$-productions, then $L(\mathcal G_1)=L(\mathcal G)-\{\epsilon\}$</h5><dl><dt>Proof</dt><dd>By inducting of the length of the derivation we can prove,
$$
A\xRightarrow[\mathcal G_1]{*}w\iff A\xRightarrow[\mathcal G]{*}w\text{ and }w\ne\epsilon
$$</dd></dl><h4 id=eliminating-unit-productions>Eliminating Unit Productions</h4><p>Algorithm to identify all unit pairs,</p><ul><li><em>Basis</em>: $(A,A)$ is a unit pair for any variable $A$. That is, $A\xRightarrow{*}A$ by zero steps.</li><li><em>Induction</em>: suppose we have determined that $(A,B)$ is a unit pair, and $B\rightarrow C$ is a production, where $C\in V$ then $(A,C)$ is a unit pair.</li></ul><p>To eliminate all unit productions, we proceed by creating a new grammar $\mathcal G_1$ as follows,</p><ol><li>Find all the unit pairs of $\mathcal G$.</li><li>For each unit pair $(A,B)$, add to $P_1$ all the productions $A\rightarrow\alpha$, where $B\rightarrow\alpha$ is a non-unit production in $P$.</li></ol><h5 id=theorem--if-grammar-mathcal-g_1-is-constructed-from-grammar-mathcal-g-by-the-algorithm-described-above-for-eliminating-unit-productions-then-lmathcal-g_1lmathcal-g><strong>Theorem</strong> : If grammar $\mathcal G_1$ is constructed from grammar $\mathcal G$ by the algorithm described above for eliminating unit productions, then $L(\mathcal G_1)=L(\mathcal G)$.</h5><h4 id=chomsky-normal-form>Chomsky Normal Form</h4><p>We can show that every CFL (without $\epsilon$) can be generated by a CFG in which all productions are of the form,</p><ul><li>$A\rightarrow BC$</li><li>$A\rightarrow a$</li></ul><p>To convert a normalized CFG to it&rsquo;s Chomsky form,</p><ol><li>Arrange all the bodies of length 2 or more so that they only contain variables. Thus if a terminal is present in add a new variable.</li><li>Break bodies of length 3 or more into a cascade of productions, each with body of 2 variables.</li></ol><h5 id=theorem--if-mathcal-g-is-a-cfg-whose-language-contains-at-least-one-string-other-than-epsilon-then-there-is-a-grammar-mathcal-g_1-in-chomsky-normal-form-such-that-lmathcal-g_1lmathcal-g-epsilon><strong>Theorem</strong> : If $\mathcal G$ is a CFG whose language contains at least one string other than $\epsilon$, then there is a grammar $\mathcal G_1$ in Chomsky Normal Form, such that $L(\mathcal G_1)=L(\mathcal G)-\{\epsilon\}$</h5><h3 id=pumping-lemma-for-cfls>Pumping Lemma for CFLs</h3><h4 id=size-of-parse-tree>Size of Parse Tree</h4><blockquote><p>For a grammar $\mathcal G$ in Chomsky Nornal Form, a parse tree with longest path $n$ and yield $w$, $|w|\le 2^{n-1}$</p></blockquote><h4 id=statement-of-pumping-lemma>Statement of Pumping Lemma</h4><h5 id=pumping-lemma-for-context-free-languages--let-l-be-a-cfl-then-there-exists-a-constant-n-such-that-if-z-is-any-string-in-l-such-that-z-is-at-least-n-then-we-can-write-zuvwxy-such-that><strong>Pumping Lemma for context-free languages</strong> : Let $L$ be a CFL. Then there exists a constant $n$ such that if $z$ is any string in $L$ such that $|z|$ is at least $n$, then we can write $z=uvwxy$ such that,</h5><h5 id=1-vwxle-n>1. $|vwx|\le n$</h5><h5 id=2-vxneepsilon>2. $vx\ne\epsilon$</h5><h5 id=3-for-all-ige0-uviwxiyin-l>3. For all $i\ge0$, $uv^iwx^iy\in L$</h5><h4 id=applications-of-pumping-lemma>Applications of Pumping Lemma</h4><p>Can be used to disprove a language being CFL by the following game,</p><ol><li>Player 1 picks a language $L$ that we want to show is not CFL.</li><li>Player 2 picks an unknown $n$.</li><li>Player 1 picks a $z$ based on $n$ as parameter.</li><li>Player 2 breaks $z$ into $uvwxy$, such that $|vwx|\le n$ and $vx\ne\epsilon$.</li><li>Player 1 wins if they can pick an $i$ and show that $uv^iwx^iy$ is not in $L$.</li></ol><h3 id=closure-properties-1>Closure Properties</h3><dl><dt>Substitution $s:\Sigma\rightarrow\mathcal P(\Sigma_1^*)$</dt><dd>For every symbol $a\in\Sigma$, $s(a)=L_a$ where $L_a$ is a language on $\Sigma_1$ Similarly for a word $w\in\Sigma^*$<ul><li><em>Basis</em>: If $w=\epsilon$ then $s(\epsilon)=\epsilon$</li><li><em>Induction</em>: $s(w)=s(w[:-1])\cdot s(w[-1])$</li></ul></dd></dl><h4 id=substitution-theorem>Substitution Theorem</h4><h5 id=theorem-if-l-is-a-cfl-over-sigma-and-s-is-a-substitution-on-sigma-such-that-sa-is-a-cfl-for-each-ainsigma-then-sl-is-a-cfl><strong>Theorem</strong>: If $L$ is a CFL over $\Sigma$ and $s$ is a substitution on $\Sigma$ such that $s(a)$ is a CFL for each $a\in\Sigma$, then $s(L)$ is a CFL.</h5><dl><dt>Proof</dt><dd>In any Parse tree of a grammar $\mathcal G$ of the original
language $L$, we replace the terminal symbols by the roots of parse trees of the language substituted at that terminal. This way a string $w$ in in $L(\mathcal G&rsquo;)$ iff $w$ is in $s(L)$.</dd></dl><h4 id=applications-of-the-substitution-theorem>Applications of the Substitution Theorem</h4><h5 id=theorem-all-cfls-are-closed-under-the-following-operations-><strong>Theorem</strong>: All CFLs are closed under the following operations:-</h5><ol><li>Union
Proof: $L_1$ and $L_2$ be CFLs. Then $L_1\cup L_2$ is the language $s(L)$ where $L$ is the language $\{0,1\}$ and $s$ is the substitution defined by $s(1)=L_1$ and $s(0)=L_2$.</li><li>Concatenation
Proof: $L=\{01\}$, $s(1)=L_1$, $s(0)=L_2$</li><li>Closure
Proof: $L=\{1\}^*$, $s(1)=L_1$</li><li>Homomorphism
Proof: $s(a)=\{h(a)\}\forall a\in\Sigma$ then $h(L)=s(L)$ where $h:\Sigma\rightarrow\Sigma$</li></ol><h4 id=reversal-1>Reversal</h4><h5 id=theorem-if-l-is-a-cfl-then-so-is-lr><strong>Theorem</strong>: If $L$ is a CFL then so is $L^R$.</h5><dl><dt>Proof</dt><dd>If $\mathcal G$ is the grammar for $L$ then $\mathcal G^R=(V,T,P^R,S)$ is the grammar for $L^R$ where,
$$
P^R=\{A\rightarrow\alpha^R:A\rightarrow\alpha\in P\}
$$</dd></dl><h4 id=intersection-with-regular-language>Intersection with Regular Language</h4><h5 id=theorem-if-l-is-a-cfl-and-r-is-a-rl-then-lcap-r-is-a-cfl><strong>Theorem</strong>: If $L$ is a CFL and $R$ is a RL then $L\cap R$ is a CFL.</h5><dl><dt>Proof</dt><dd>Involves PDA :(</dd></dl><h3 id=descision-properties-1>Descision Properties</h3><h2 id=turing-machines>Turing Machines</h2><dl><dt>Turing Machine $M(Q, \Sigma, \Gamma, \delta, q_0, B, F)$</dt><dd><ul><li>$Q$: Finite set of states of finite control</li><li>$\Sigma$: Finite set of input symbols</li><li>$\Gamma$: Complete set of tape symbols; $\Sigma$ is always a subset of $\Gamma$ and $\Sigma\sube\Gamma$</li><li>$\delta$: Transition funtion such that $\delta: Q\times\Gamma\rightarrow Q\times\Gamma\times\{L,R\}$ and if $\delta(p, X)=(q, Y, L/R)$ means<ul><li>Control state goes from $p$ to $q$</li><li>Current tape symbol $X$ is replaced by $Y$</li><li>Tape is shifted towards left/right based on L/R.</li></ul></li><li>$q_0$: The start state thus $q_0\in Q$</li><li>$B$: The blank symbol thus $B\in\Gamma$</li><li>$F$: The set of final accepting states thus $F\sube Q$</li></ul></dd><dt>Instantaneous Description $ID(X_1X_2\cdots X_{i-1}qX_i\cdots X_n)$</dt><dd><ul><li>$q$ is the state of the Turing machine</li><li>Tape is scanning the $i\text{th}$ symbol from the left</li><li>$X_1X_2\cdots X_n$ is the portion of the tape between the leftmost and the rightmost non-blank.</li></ul></dd><dt>Moves $(\vdash$ or $\vdash^{*})$</dt><dd>If $\delta(q,X_i)=(p,Y,\alpha)$<ul><li>$\alpha=L$
$$
X_1X_2\cdots X_{i-1}qX_i\cdots X_n\vdash X_1\cdots X_{i-2}pX_{i-1}Y\cdots X_n
$$</li><li>$i=1$ and $\alpha=L$
$$
qX_1\cdots X_n\vdash pBYX_2\cdots X_n
$$</li><li>$i=n$, $Y=B$ and $\alpha=L$
$$
X_1\cdots X_{n-1}qX_n\vdash X_1\cdots X_{n-2}pX_{n-1}
$$</li><li>$\alpha=R$
$$
X_1X_2\cdots X_{i-1}qX_i\cdots X_n\vdash X_1\cdots X_{i-1}YpX_{i+1}\cdots X_n
$$</li><li>$i=n$ and $\alpha=R$
$$
X_1\cdots X_{n-1}qX_n\vdash X_1\cdots X_{n-1}YpB
$$</li><li>$i=1$, $Y=B$ and $\alpha=R$
$$
qX_1\cdots X_n\vdash pX_2\cdots X_n
$$</li></ul></dd><dt>Transition diagram $G(V,E)$</dt><dd><ol><li>$V=Q$</li><li>$E=\{q\xrightarrow{X/Y\rightarrow}p:\delta(q,X)=(p,Y,R)\}\cup\{q\xrightarrow{X/Y\leftarrow}p:\delta(q,X)=(p,Y,L)\}$</li><li>An arrow pointing into $q_0$</li><li>All states in $F$ are double-circled</li></ol></dd><dt>Language of Turing Machine $(L(M))$</dt><dd>$$
L(M) = \{w:q_0w\vdash^{*}\alpha p\beta, p\in F\}
$$</dd></dl><blockquote><p>The set of languages accepted by a Turing Machine is called Recursively Enumerable</p></blockquote><blockquote><p>Another notion of acceptance is when a Turing Machine halts on words in the language.</p></blockquote><h3 id=programming-techniques>Programming Techniques</h3><ol><li><strong>Storage in state</strong>: Viewing the control states as tuples to store information</li><li><strong>Multiple Tracks</strong>: Using multiple tracks to store data, marks, etc. in a useful way.</li><li><strong>Subroutines</strong>: Creating copies of con trol states and transitions every time a subroutine is to be used from its initial state.</li></ol><h3 id=extensions-to-basic-definition>Extensions to Basic definition</h3><ol><li><strong>Multitape Turing Machines</strong>: Reads from more than one tapes.</li><li><strong>Non-deterministic Turing Machines</strong>: $\delta:Q\times\Gamma\rightarrow\mathcal P(Q\times\Gamma\times\{R,L\})$</li></ol><h3 id=restrictions-on-basic-definition>Restrictions on Basic definition</h3><ol><li><strong>TM with semi-infinite tapes</strong></li><li><strong>Multistack Machines</strong></li><li><strong>Counter Machines</strong></li></ol><h2 id=undecidability>Undecidability</h2><dl><dt>Code for TM $(w_M)$</dt><dd>An elaborate way to encode $M$ and it&rsquo;s components into a finite bit-string that is unique to $M$.</dd><dt>Diagonalization Language $(L_d)$</dt><dd>We enumerate all possible Turing Machines $M_i$ by enumerating their codes $w_i$. Now construct a table in which $(i,j)\text{th}$ entry is $1$ if $w_i$ is accepted by $M_j$ else it is $0$. Take the diagonal of this table and complement it to get the characteristic vector for $L_d$. The $i\text{th}$ bit of this characteristic vector denotes the membership of $w_i$ in $L_d$.</dd></dl><h5 id=theorem--l_d-is-not-recursively-enumerable><strong>Theorem</strong> : $L_d$ is not recursively enumerable.</h5><dl><dt>Proof</dt><dd>There is no $M_i$ in the table as described above that matches the characteristic vector of $L_d$ over $w_i\text{&rsquo;s}$ therefore $\not\exist M,\ L_d=L(M)$.</dd><dt>Recursive Languages</dt><dd>Languages that have a Turing Machine that accepts all the words in the language and halts without accepting on all the words not in the language.</dd></dl><blockquote><p>Recursive(Algorithmic) $\sube$ RE(Undecidable) $\sube$ Not RE</p></blockquote><blockquote><p>If $L$ is recursive then $\bar L$ is also recursive.</p></blockquote><blockquote><p>If $L$ and $\bar L$ are RE then they are both recursive.</p></blockquote><h5 id=rices-theorem--every-nontrivial-property-of-the-re-languages-is-undecidable><strong>Rice&rsquo;s Theorem</strong> : Every nontrivial property of the RE languages is undecidable.</h5><blockquote><p>$L_u$ a.k.a. the universal language containing all the pairs $(M,w)$ where $M$ is a code for TM which accepts $w$.
$L_u$ is <strong>Undecidable</strong>.</p></blockquote><h3 id=post-correspondence-problem>Post Correspondence Problem</h3><dl><dt>Post Correspondence Problem $(PCP)$</dt><dd>Given two lists of strings $A=[w_1,w_2,\dots w_k]$ and $B=[x_1,x_2,\dots x_k]$ with equal length, find a sequence of indices $i_1, i_2, \dots, i_m$ where,
$$
w_{i_1}w_{i_2}\cdots w_{i_m}=x_{i_1}x_{i_2}\cdots x_{i_m}
$$</dd><dt>Modified PCP $(MPCP)$</dt><dd>Given two lists of strings $A=[w_1,w_2,\dots w_k]$ and $B=[x_1,x_2,\dots x_k]$ with equal length, find a sequence of indices $i_1, i_2, \dots, i_m$ where,
$$
w_1w_{i_1}w_{i_2}\cdots w_{i_m}=x_1x_{i_1}x_{i_2}\cdots x_{i_m}
$$</dd></dl><h5 id=theorem--mpcp-reduces-to-pcp><strong>Theorem</strong> : MPCP reduces to PCP</h5><dl><dt>Proof</dt><dd>Given an instance of MPCP with lists $A$ and $B$ alphabets not containing $*$ and $\$$ we define a PCP instance with lists $C=[y_0,y_1,\dots,y_{k+1}]$ and $D=[z_0,z_1,\dots,z_{k+1}]$<ol><li>For $i=1,2,\dots,k$ let $y_i=w_i$ with a $*$ after each symbol and let $z_i=x_i$ with a $*$ before each symbol of $x_i$</li><li>$y_0=*y_1$ and $z_0=z_1$</li><li>$y_{k+1}=\$$ and $z_{k+1}=*\$$</li></ol></dd></dl><h5 id=theorem--mpcp-is-undecidable><strong>Theorem</strong> : MPCP is Undecidable.</h5><dl><dt>Proof</dt><dd>Reduce $L_u$ acceptability to MPCP.</dd></dl><h2 id=intractable-problems>Intractable Problems</h2><dl><dt>Polynomial Time $(\mathcal P)$</dt><dd>Class of languages which are accepted by a Turing machine $M$ with a time complexity $T(n)$ such that whenever $M$ is given an input $w$ of length $n$, $M$ halts after making at most $T(n)$ moves, regardless of whether or not $w$ is accepted.</dd><dt>Nondeterministic Polynomial Time $(\mathcal{NP})$</dt><dd>Class of languages which are accepted by a nondeterministic Turing machine $M$ with a time complexity $T(n)$ such that whenever $M$ is given an input $w$ of length $n$, $M$ halts after making at most $T(n)$ moves.<p>A language $L$ belongs to $\mathcal{NP}$ iff $\exist$ a language $L_1\in\mathcal P$:-</p><ul><li>if for every $x\in L \exist$ some additional input $y$ with (with $y‚â§p(|x|)$) s.t. the string $x#y\in L_1$ (where $#$ represents some kind of pair).</li><li>if $x\not\in L$ then for no string $y$ we have $x#y\in L_1$.</li><li>Here, $y$ is a proof or certificate that $x\in L$.</li></ul></dd></dl><blockquote><p>A problem $A$ is said to be <em><strong>Polynomial-time reducible</strong></em> to problem $B$ if there exists a $\mathcal P$ TM which can generate solutions for $A$ given a constant time TM for solving $B$ that can be used as a subroutine.</p></blockquote><dl><dt>Complement of $\mathcal{NP}$ $(\text{Co-}\mathcal{NP})$</dt><dd>Complement of languages in $\mathcal{NP}$.</dd></dl><blockquote><p>If $\mathcal P = \mathcal{NP}$, then Co-$\mathcal{NP}$ will also be $\mathcal{NP}$. But, whether $\mathcal P$ is equal to $\mathcal{NP}$ (or not) is not proven yet.</p></blockquote><blockquote><p>Language of Composite numbers is in $\mathcal{NP} and so is the language of Prime Numbers$</p></blockquote><h3 id=np-complete-problems>NP-Complete Problems</h3><ul><li>SAT</li><li>CNF-SAT</li><li>3-SAT</li><li>Maximal Independent Set</li><li>Minimal Vertex Cover</li><li>Hamiltionian path</li><li>Travelling Salesman Problem</li></ul></article></main><footer id=footer><div><span>¬© 2019</span> - <span>2023</span></div><div><span>Powered by</span>
<a class=link href=https://gohugo.io/>Hugo</a>
<span>üç¶ Theme</span>
<a class=link href=https://github.com/queensferryme/hugo-theme-texify>TeXify</a></div><div class=footnote><span>Follow me on <a class=link href=https://github.com/queensferryme>GitHub</a>,
<a class=link href=https://twitter.com/queensferryme>Twitter</a> or
<a class=link href=/index.xml>RSS</a> |
<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a></span></div></footer></div></body></html>