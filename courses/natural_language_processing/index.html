<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=generator content="Hugo 0.101.0"><link rel="shortcut icon" href=https://cdn.jsdelivr.net/gh/dsrkafuu/dsr-cdn-main@1/images/favicons/dsrca.ico><title>Natural Language Processing - Scrolls</title><meta name=keywords content="Computer-Science,Machine-Learning"><meta property="og:title" content="Natural Language Processing"><meta name=twitter:title content="Natural Language Processing"><meta property="og:type" content="article"><meta property="og:url" content="https://adityakadoo.github.io/Scrolls/courses/natural_language_processing/"><meta property="og:description" content="Part of Speech Tagging HMM-based Tagging Parameters Input: A sequence of words and labels Output: A sequence of labels for every word Penn tag-set is generally used for POS tagging in english language.
Hidden Markov Model There are 2 kinds of probabilities:
Bigram Probabilities $(P(t_1|t_0))$ : Probability of current word being tag $t_1$ when previous word was tagged $t_0$. Lexical Probabilities $(P(w|t))$: Probability of word $w$ given it is tagged $t$."><meta name=twitter:description content="Part of Speech Tagging HMM-based Tagging Parameters Input: A sequence of words and labels Output: A sequence of labels for every word Penn tag-set is generally used for POS tagging in english language.
Hidden Markov Model There are 2 kinds of probabilities:
Bigram Probabilities $(P(t_1|t_0))$ : Probability of current word being tag $t_1$ when previous word was tagged $t_0$. Lexical Probabilities $(P(w|t))$: Probability of word $w$ given it is tagged $t$."><meta name=twitter:card content="summary"><meta property="article:published_time" content="2022-08-24T09:49:01+05:30"><meta property="article:modified_time" content="2022-08-24T09:49:01+05:30"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://adityakadoo.github.io/Scrolls/assets/css/fuji.min.css></head><body data-theme=auto data-theme-auto=false><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://adityakadoo.github.io/Scrolls/>Scrolls</a></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://adityakadoo.github.io/Scrolls/courses/natural_language_processing/>Natural Language Processing</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2022-08-24</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/computer-science>Computer-Science</a>&nbsp;<a href=/tags/machine-learning>Machine-Learning</a>&nbsp;</span></div><div class="post-content markdown-body"><h2 id=part-of-speech-tagging>Part of Speech Tagging</h2><h3 id=hmm-based-tagging>HMM-based Tagging</h3><h4 id=parameters>Parameters</h4><ul><li><em>Input</em>: A sequence of words and labels</li><li><em>Output</em>: A sequence of labels for every word</li></ul><blockquote><p>Penn tag-set is generally used for POS tagging in english language.</p></blockquote><h4 id=hidden-markov-model>Hidden Markov Model</h4><p>There are 2 kinds of probabilities:</p><ol><li>Bigram Probabilities $(P(t_1|t_0))$ : Probability of current word being tag $t_1$ when previous word was tagged $t_0$.</li><li>Lexical Probabilities $(P(w|t))$: Probability of word $w$ given it is tagged $t$.</li></ol><blockquote><p>By Markov assumption, current word&rsquo;s tag only depends on previous word&rsquo;s tag.</p></blockquote><h4 id=viterbi-algorithm>Viterbi Algorithm</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>#define BProb(t1,t0) () </span><span style=color:#75715e>// Bigram
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#75715e>#define LProb(w,t) () </span><span style=color:#75715e>// Lexical
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> viterbi(vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> sentence, vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> labels){
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> n <span style=color:#f92672>=</span> sentence.size();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> l <span style=color:#f92672>=</span> labels.size();
</span></span><span style=display:flex><span>    <span style=color:#75715e>// labels[0] = &#34;^&#34;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    vector<span style=color:#f92672>&lt;</span>vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;&gt;</span> dp(n<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>, vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>(l, <span style=color:#ae81ff>0</span>));
</span></span><span style=display:flex><span>    vector<span style=color:#f92672>&lt;</span>vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;&gt;</span> plabel(n<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>, vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(l,<span style=color:#ae81ff>0</span>));
</span></span><span style=display:flex><span>    dp[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;i<span style=color:#f92672>&lt;</span>n;i<span style=color:#f92672>++</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> j<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;j<span style=color:#f92672>&lt;</span>l;j<span style=color:#f92672>++</span>);
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> k<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;k<span style=color:#f92672>&lt;</span>l;k<span style=color:#f92672>++</span>){
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>float</span> p <span style=color:#f92672>=</span> dp[i][k]
</span></span><span style=display:flex><span>                    <span style=color:#f92672>*</span> BProb(labels[j],labels[k])
</span></span><span style=display:flex><span>                    <span style=color:#f92672>*</span> LProb(sentence[i],labels[j]);
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span>(dp[i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>][j]<span style=color:#f92672>&lt;</span>p){
</span></span><span style=display:flex><span>                    dp[i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>][j] <span style=color:#f92672>=</span> p;
</span></span><span style=display:flex><span>                    plabel[i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>][j] <span style=color:#f92672>=</span> k;
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>    vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> res(sentence.begin(),sentence.end());
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> ptr<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;i<span style=color:#f92672>&lt;</span>l;i<span style=color:#f92672>++</span>)
</span></span><span style=display:flex><span>        ptr <span style=color:#f92672>=</span> dp[n][ptr]<span style=color:#f92672>&lt;</span>dp[n][i] <span style=color:#f92672>?</span> i : ptr;
</span></span><span style=display:flex><span>    res[n<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> res[n<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]<span style=color:#f92672>+</span><span style=color:#e6db74>&#34;_.&#34;</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span>n<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>;i<span style=color:#f92672>&gt;</span><span style=color:#ae81ff>0</span>;i<span style=color:#f92672>--</span>){
</span></span><span style=display:flex><span>        ptr <span style=color:#f92672>=</span> slabel[i][ptr];
</span></span><span style=display:flex><span>        res[i<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#34;_&#34;</span><span style=color:#f92672>+</span>labels[ptr];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> res;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=discriminative-learning>Discriminative Learning</h3><p>HMM based POS tagging cannot handle &ldquo;free word order&rdquo; and &ldquo;agglutination&rdquo; well.</p><h4 id=feature-engineering>Feature Engineering</h4><ol><li>Word-based features<ul><li>$f_{21}$: Dictionary index of the current word</li><li>$f_{22}$: Dictionary index of the previous word</li><li>$f_{23}$: Dictionary index of the next word</li></ul></li><li>Part of Speech tag-based features<ul><li>$f_{24}$: Index of POS of previous word</li></ul></li><li>Morphology-based features<ul><li>$f_{25}$: does the current word have a noun suffix like &rsquo;s&rsquo;, &rsquo;es&rsquo;, &lsquo;ies&rsquo;, etc.</li><li>$f_{26}$: does the current word have a verbal suffix like &rsquo;d&rsquo;, &rsquo;ed&rsquo;, &rsquo;t&rsquo;, etc.</li><li>$f_{27}$ and $f_{28}$: above two for previous word.</li><li>$f_{29}$ and $f_{2,10}$: above two for next word.</li></ul></li></ol><h4 id=morphology>Morphology</h4><dl><dt>Morphemes</dt><dd>Smallest meaning-bearing units forming a word.
e.g.: In &ldquo;quickly&rdquo;, &ldquo;quick&rdquo; and &ldquo;ly&rdquo;.</dd></dl><ul><li><strong>Analytic Languages</strong>: Morphemes largely separate from one another.</li><li><strong>Synthetic Languages</strong>: Joins the morphemes.</li></ul><dl><dt>Syncretism</dt><dd>Overloading of roles per morpheme is called <em><strong>syncretism</strong></em>.
e.g.: &ldquo;will go&rdquo;: since number and person are indeterminate here</dd></dl><h4 id=maximum-entropy-markov-model>Maximum Entropy Markov Model</h4><p>$$
P(t_i=t|F_i)=\dfrac{e^{\sum_{j=1.k}\lambda_jf_{ij}}}{{\sum_{t&rsquo;\in S}}e^{\sum_{j=1.k}\lambda_jf_{ij}(t&rsquo;)}}
$$</p><h4 id=beam-search-algorithm>Beam Search Algorithm</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>#define WProb(t,w) ()
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> beam_search(vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> sentence, vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> labels){
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> n <span style=color:#f92672>=</span> sentence.size();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> l <span style=color:#f92672>=</span> labels.size();
</span></span><span style=display:flex><span>    <span style=color:#75715e>// labels[0] = &#34;^&#34;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    vector<span style=color:#f92672>&lt;</span>string<span style=color:#f92672>&gt;</span> best1,best2;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>float</span> p1,p2;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Iterate through all cases and keep track of best 2
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>return</span> res;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=parsing>Parsing</h2><h3 id=cyk-parsing>CYK Parsing</h3></div></article></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/Scrolls/tags/computer-science/>Computer-Science</a></span>
<span><a href=/Scrolls/tags/machine-learning/>Machine-Learning</a></span>
<span><a href=/Scrolls/tags/programming-languages/>Programming-Languages</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#part-of-speech-tagging>Part of Speech Tagging</a><ul><li><a href=#hmm-based-tagging>HMM-based Tagging</a></li><li><a href=#discriminative-learning>Discriminative Learning</a></li></ul></li><li><a href=#parsing>Parsing</a><ul><li><a href=#cyk-parsing>CYK Parsing</a></li></ul></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/Scrolls/tags/computer-science/>Computer-Science</a></span>
<span><a href=/Scrolls/tags/machine-learning/>Machine-Learning</a></span>
<span><a href=/Scrolls/tags/programming-languages/>Programming-Languages</a></span></div></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2022
<a href=https://adityakadoo.github.io/Scrolls/></a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js></script>
<script defer src=/Scrolls/assets/js/fuji.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css><script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js></script>
<script>renderMathInElement(document.querySelector("div.content"),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})</script></body></html>